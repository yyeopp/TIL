# Chapter 08: 가상메모리

---

운영체제는 프로세스의 빠른 수행을 위해, 보통 몇몇 프로그램에게 집중적으로 메모리를 할당했다가 회수하는 방식을 채택한다.

프로그램이 실행되기 위해서는 프로세스 주소 공간 **전체가** 메모리에 올라와야 하는 것은 아니므로, 운영체제는 당장 필요한 부분만 메모리에 올려놓고 그렇지 않은 부분은 **디스크 스왑 영역**에 내려놨다가 필요할 때 가져와서 사용한다.

즉, 프로그램 입장에서는 **물리 메모리의 크기**에 대해 생각할 필요가 없다. 각기 **0번지**부터 시작하는 자신만의 메모리 주소 공간을 가정하고 실행되는데, 이러한 공간을 **가상메모리**라고 부른다.

---

## 요구 페이징

요구 페이징은 프로그램 실행 시, 프로세스를 구성하는 모든 **페이지**를 한꺼번에 메모리에 올리는 것이 아니라 **당장 사용될 페이지만**을 올리는 방식이다.

- 특정 페이지에 대해 **CPU 요청**이 들어온 후에야 메모리에 적재하게 된다.

당연히 **메모리 사용량이 감소**하고, 메모리에 대한 **입출력 오버헤드도 감소**한다.

결과적으로 **응답시간이 감소**하고, **더 많은 프로세스가 수용**될 수 있다.

- 프로그램을 구성하는 페이지 중 일부만을 메모리에 적재하기 때문에 물리 메모리의 용량 제약을 벗어날 수 있는 것.

메모리에 올라오지 않는 페이지는 **디스크 스왑 영역**에 존재한다.

운영체제는 요구 페이징 기법 사용 시, **유효-무효 비트**를 두어 **어떤 페이지가 메모리에 존재하는지**를 표시하게 된다.

- 해당 비트는 **페이지 테이블**의 **각 항목별**로 저장된다.

- 메모리에 적재될 때 유효값으로, 스왑 영역으로 쫓겨날 때 무효값으로 변경된다.

CPU가 참조하려는 페이지가 현재 메모리에 올라와 있지 않아 비트값이 무효로 세팅되어 있는 경우에 대해, **페이지 부재**가 일어났다고 한다.

### 요구 페이징의 페이지 부재 처리

CPU가 무효 페이지에 접근하면, 주소 변환 담당 하드웨어인 **MMU**가 **페이지 부재 트랩**을 발생시킨다. 그럼 운영체제는 커널모드에 돌입하여 **페이지 부재 처리루틴**을 호출한다.

- 우선, 운영체제는 해당 페이지에 대한 접근이 적법한지 우선 체크한다.
  
  - 사용되지 않는 주소 영역이거나, 접근 권한을 위반한 경우 프로세스를 종료시킨다.

- 적법한 것이라면, 물리 메모리에서 **비어 있는 프레임**을 할당받아 그 공간에 페이지를 읽어온다.
  
  - 만약 비어 있는 프레임이 없다면, 기존 페이지 중 하나를 **스왑 아웃**시킨다.

- 디스크로부터 페이지를 읽어오는 작업은 시간이 꽤 소요되기 때문에, 페이지 부재를 발생시킨 프로세스는 CPU를 빼앗기고 봉쇄 상태로 전환된다.
  
  - **PCB**에 레지스터 상태, 프로그램 카운터값 등을 확실히 저장할 수 있도록 할 필요가 있다.

- 디스크 I/O 완료 인터럽트가 발생하면, 페이지 테이블에서 비트를 **유효**로 설정하고, 봉쇄됐던 프로세스를 준비 큐로 이동시킨다.

### 요구 페이징의 성능

가장 큰 성능 요소는, **페이지 부재의 발생 빈도**이다.

- 디스크에서 메모리로 페이지를 읽어오는 오버헤드가 매우 크기 때문.

성능 측정은, **요청한 페이지를 참조하는 데 걸리는 유효 접근시간**으로 측정한다.

---

## 페이지 교체

물리 메모리에 빈 프레임이 없어서 기존 페이지를 스왑 아웃시키는 작업을 **페이지 교체**라고 한다.

이 때 어떤 페이지를 쫓아낼 것인지 결정하는 알고리즘은 **교체 알고리즘**이라 한다.

- 목표는 **페이지 부재율**을 최소화하는 것.
  
  - 참조될 가능성이 가장 적은 페이지를 선택해서 스왑 아웃하는 것이, 성능 향상으로 직결되기 때문

- 알고리즘 성능은, 주어진 페이지 참조열에 대해 페이지 부재율을 계산하여 평가한다.
  
  - 요청된 페이지가 메모리에 있으면 hit, 없으면 페이지 부재.

### 최적 페이지 교체

최적의 알고리즘에 대해 정답은 정해져 있다. 

물리 메모리에 존재하는 페이지 중 **가장 먼 미래에 참조될 페이지를 쫓아내면 된다**.

- 이를 **빌레디의 최적 알고리즘**이라고 한다.

문제는, **페이지 참조열**이 미리 주어진 상태를 가정했을 때만 적용할 수 있다는 점.

실제 시스템, 온라인에서 사용 가능한 방법이 아니다. **오프라인 알고리즘**에 불과하다.

그래서 다른 알고리즘 성능의 **상한선**으로서의 의미만을 가진다.

### 선입선출(FIFO) 알고리즘

페이지 교체 시 당시, 물리 메모리에서 **가장 먼저 올라온** 페이지를 우선 내쫓는 방식.

- 페이지의 **향후 참조 가능성**을 고려하지 않는다.

특정 경우에는, 물리 메모리의 **공간을 늘렸는데 페이지 부재가 잦아져서 성능이 악화되는** 상황이 나타날 수도 있다.

- 이를 **FIFO의 이상현상**이라고 부른다.

### LRU 알고리즘

Least Recently Used.

알고리즘 성능 향상을 위해 **향후 참조 가능성**을 고려하지 않을 수가 없다.

이 때, 페이지 참조 성향 중 중요한 성질로 **시간지역성**이 존재한다.

- 최근 참조된 페이지가, 가까운 미래에 다시 참조될 가능성이 높다는 성질.

LRU에서는 이를 이용하여, **가장 오래전에 참조가 이루어진 페이지**를 쫓아낸다.

- FIFO의 이상현상은 더 이상 나타나지 않을 수 있다.

### LFU 알고리즘

Least Frequently Used.

물리 메모리에 존재하는 페이지 중 **과거에 참조 회수가 가장 적었던 페이지**를 교체한다.

- 참조 회수가 동등한 경우 **개중에 더 오래 전에 참조된 페이지**를 선택하는 편.

참조 회수를 계산하는 방식에 따라 분류가 나뉘는데,

- Incache-LFU는 페이지가 **메모리에 올라온 후부터** 참조 회수를 카운트한다.

- Perfect-LFU는 특정 페이지의 **과거 총 참조 회수**를 모두 카운트한다.

Perfect-LFU가 보다 정확하다고 볼 수는 있으나, 과거 기록을 모두 보관하고 있어야 한다는 오버헤드가 큰 편이다.

기존 기록을 참조하는 LRU보다 더 **오랜 기록**을 참조한다고 볼 수 있어 장점이 있으나,

- 시간에 따른 페이지 참조 경향의 변화를 반영하지 못하고

- LRU보다 구현이 복잡하다는 단점이 있다.

### 클럭 알고리즘

앞선 알고리즘과 달리, **하드웨어적 지원**을 통해 운영 오버헤드를 절감한 방식.

방식 자체는 **LRU를 근사**시킨 알고리즘이다.

- 가장 오래전에 참조된 페이지가 아닌, 오랫동안 참조되지 않은 페이지 **중 하나를** 교체하는 것.

- LRU에 비해 훨씬 빠르고 상당히 효율적이기 때문에, 대부분의 시스템에서 클럭 알고리즘을 사용한다.

교체할 페이지 선정을 위해, 페이지 프레임들의 **참조비트**를 **순차적으로** 조사한다.

- 각 프레임에 있는 참조비트는 참조될 때마다 1로 세팅된다.

- 클럭 알고리즘은 메모리에 올라와 있는 프레임을 시곗바늘처럼 순회하는데,
  
  - 참조비트가 1이면 0으로 바꾼 후 전진하고
  
  - 참조비트가 0이면 해당 페이지를 교체한다.

결과적으로, **시곗바늘이 한 바퀴 도는 동안은** 페이지가 메모리에 유지될 수 있고, 그러는 사이에 참조가 된 페이지는 교체되지 않고 유지될 수 있다.

- 페이지 부재율이 상당히 줄어들 수 있다.

- **2차 기회 알고리즘**이라고도 한다.

---

## 페이지 프레임의 할당

운영체제는 각 프로세스에게 얼마만큼의 메모리 공간을 할당할 것인지도 결정해야 한다.

- **균등할당** 방식은 모든 프로세스에게 프레임을 **균일하게** 할당하는 방식이다.

- **비례할당** 방식은 프로세스 **크기에 비례해** 프레임을 할당하는 방식이다.

- **우선순위 할당** 방식은 프로세스 **우선순위**에 따라 프레임을 할당하는 방식이다.
  
  - 우선순위는 CPU에서 당장 실행이 필요한지 여부에 따라 결정된다.

단, 위 셋은 프로세스의 페이지 참조 특성을 완전히 반영하고 있다고 보기 어렵다.

- 프로세스가 정상적으로 수행되기 위해서는 최소 수준 이상의 페이지 프레임이 할당될 필요가 있는데, 그 부분은 고려하지 않음

- 반복문이 실행 중이라면 관련 페이지가 모두 올라와 있는게 유리한데, 역시 고려되지 못함

- **최소 수준**의 메모리 양 또한 시간에 따라 달라짐.

즉 상황을 종합적으로 고려하여 **프로세스 별 최소한의 메모리 요구량**을 충족시키는 할당 방식이 적용될 필요가 있다.

---

## 전역교체와 지역교체

교체 대상이 될 **프레임의 범위를 어떻게 정할지**에 따라 교체 방법을 구분한다.

- **전역교체**는, **모든** 페이지 프레임이 교체 대상이 될 수 있다.

- **지역교체**는, 현재 수행 중인 프로세스에게 **할당된 프레임 내**에서만 교체 대상을 선정할 수 있다.
  
  - 프로세스마다 페이지 프레임이 미리 할당된 것을 전제로 한다.

전역교체는, **전체 메모리**를 각 프로세스가 공유해서 사용한다. 페이지 교체 대상을 선정할 때, 해당 페이지가 어떤 프로세스에 속한 것인지 고려하지 않는다.

- 프로세스 간에 **프레임을 빼앗아올 수 있는** 방식이기 때문에, 각 프로세스에 할당된 메모리 양이 가변적이다.

지역교체는, 프로세스별로 페이지 프레임이 할당된 상태다.

- 프로세스에 할당된 메모리 양이 비가변적이다.

---

## 스레싱(thrashing)

프로세스가 **최소한의 페이지 프레임**을 할당받지 못할 경우 **페이지 부재율**이 크게 상승해 심각한 성능 이슈가 발생할 수 있다.

- 이와 같은 현상을 **스래싱**이라 부른다.

기본적으로 운영체제는 CPU 이용률이 낮을 경우 **메모리에 동시에 올리는 프로세스 수가 적다**고 판단한다.

- CPU 이용률이 낮다는 건 준비 큐가 비었다는 것이고

- 준비 큐가 비었다는 건 기존 프로세스가 모두 I/O 작업 중이라 대신 CPU를 받아갈 프로세스가 없다는 것이고

- 그건 프로세스 수 자체가 적다는 것.

메모리에 동시에 올라가는 프로세스의 수를 **다중 프로그래밍의 정도**(**MPD**)라고 부르는데, CPU 이용률이 낮을 때 운영체제는 MPD를 높인다.

근데 MPD가 너무 높으면, **각 프로세스에 할당되는 메모리 양이 지나치게 낮아진다**.

- 각 프로세스에서 발생하는 **페이지 부재**가 잦아지면 그 또한 디스크 I/O와 문맥교환으로 이어지기 때문에,

- 마치 프로세스 수가 적었을 때처럼 CPU 이용률이 급감하는 현상이 나타나게 된다.

- 여기서 CPU가 여전히 MPD를 높이는 선택을 하면, 프로세스들은 그저 페이지 교체에만 몰두하게 되고 CPU 이용률은 바닥을 찍는다.

- 이게 **스레싱**.

즉, **스레싱이 발생하지 않으면서 CPU 이용률을 최대한 높일 수 있도록 MPD를 최적화하는** 것이 중요하다.

### 워킹셋 알고리즘

프로세스는 일정 시간 동안 특정 주소 영역으로 집중적으로 참조하는 경향이 있는데, 집중적으로 참조되는 페이지들의 집합을 **지역성 집합**이라 한다.

워킹셋 알고리즘은, 지역성 집합이 **메모리에 동시에 올라가 있을 수 있도록 보장하는** 메모리 관리 알고리즘이다.

프로세스가 일정 시간 내 원활히 수행되기 위해, **한꺼번에 메모리에 올라와 있어야 하는 페이지들의 집합**을 **워킹셋**이라 정의하고, 워킹셋이 전부 올라갈 수 있는 *경우에만* 해당 프로세스에게 메모리를 할당한다.

- 이를 만족하지 않는 상황이라면 해당 프로세스 **주소 공간 전체**는 스왑 아웃된다.

구체적으로, **워킹셋 윈도우**를 사용한다.

- 워킹셋은, 워킹셋 윈도우 크기만큼의 시간 간격에 참조된 서로 다른 페이지들의 집합이다.

- 메모리에 올라와 있는 프로세스들의 워킹셋 크기 합이 프레임 수보다 크다면, 일부 프로세스는 스왑 아웃시켜 MPD를 줄인다.

- 워킹셋을 전부 할당해도 프레임이 남으면 디스크의 프로세스를 다시 올려 MPD를 높인다.

즉, 워킹셋 알고리즘에서는 프로세스들의 지역성 집합을 효과적으로 탐지할 수 있는 윈도우 크기를 결정하는 것이 중요하다.

### 페이지 부재 빈도 알고리즘

프로세스의 **페이지 부재율**을 주기적으로 조사해, 각각에 할당할 메모리 양을 동적으로 조절한다.

- 특정 프로세스의 페이지 부재율이 시스템 상한값을 넘으면 프레임을 추가로 할당하고, 하한값 이하로 떨어지면 할당된 프레임 수를 줄이는 방식.
