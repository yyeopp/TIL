# Chapter 09: 클라우드를 사용한 Docker 실행 환경 구축

---

Docker는 이미지만 있으면 동일한 인프라 환경에서 어플리케이션을 가동시킬 수 있다.

즉, 온프레미스부터 프라이빗 클라우드, 퍼블릭 클라우드 등 실행 환경을 **요구사항에 맞춰** 자유롭게 선택하면 된다.

이를 통한 어플리케이션의 **높은 이식성**이 최대의 강점이다.

- GCP의 매니지드 서비스인 Google Kubernetes Engine (GKE)를 사용해 Docker 실행 환경을 구축하는 것이 하나의 예시가 될 것.

---

## 클라우드 환경에서 Docker 오케스트레이션하기

주요 퍼블릭 클라우드 업체는 Docker 오케스트레이션을 위해 다양한 서비스를 제공하고 있다.

### 분산 환경에서의 컨테이너 운용 관리

멀티호스트로 구성된 실제 환경을 **클러스터 구성**으로 가동시키려면 컨테이너 조작뿐만 아니라 호스트 간 네트워크 연결, 스토리지 관리, 컨테이너를 어떤 호스트에서 가동시킬지 같은 **스케줄링** 기능이 필요하다. 컨테이너 정상 작동 여부를 감시할 장치도 필요하다.

- 이러한 기능을 갖추어 컨테이너를 통합 관리할 수 있는 툴을 **컨테이너 오케스트레이션 툴**이라고 한다.

#### Kubernetes

google의 엔지니어를 중심으로 개발되고 있는 오픈소스 컨테이너 오케스트레이션 툴.

제공하는 기능도 풍부하고 개발 속도가 빠르며, 도입 실적도 풍부하여 실질적인 스탠다드다.

#### Docker Engine (Swarm 모드)

Docker 자체적으로 클러스터링 기능을 제공하는 Swarm 모드가 있다. 이를 통해 여러 개의 컨테이너를 멀티호스트 환경에서 작동시키고, 하나의 명령으로 조작할 수 있다.

#### Apache Mesos, Marathon

Mesos는 오픈소스 클러스터 오케스트레이션 툴로, 몇 천 대의 호스트도 지원 가능하도록 설계되어 있다.

- 여러 호스트의 CPU나 메모리, 디스크를 추상화하여 하나의 리소스 풀로 다룰 수 있다.

**컨테이너** 오케스트레이션에 사용하려면 별도의 프레임워크가 필요한데, Marathon이 사용된다.

- 장기간에 걸쳐 계속 작동하는 어플리케이션의 실행이나 모니터링을 할 수 있다.

### 퍼블릭 클라우드가 제공하는 매니지드 서비스

일반적으로 클러스터 환경을 직접 구축하고 운용하는 것은 기술적인 난이도가 높다. 운용에 걸리는 부하 또한 시스템이 커질수록 기하급수적으로 커진다.

그래서, 충분한 스킬과 경험이 없는 경우 Docker 컨테이너를 제품 환경에서 운용할 때 **퍼블릭 클라우드가 제공하는** 매니지드 서비스를 이용하는 것이 좋다.

- 이를 통해 인프라에 관한 깊은 지식이나 경험이 없어도 높은 가용성을 가진 클러스터 환경에서 컨테이너를 운용할 수 있다.

#### Amazon EC2 Container Service

AWS EC2를 사용하는 Docker 컨테이너 관리 서비스이다.

Amazon ECS에서는 **태스크 정의**라고 하는 JSON 탬플릿을 사용해 환경을 정의한다. 

- Docker 리포지토리, 이미지, 메모리, CPU 같은 하드웨어 요구사항이나 데이터 볼륨 스토리지, 컨테이너 간 연결 등을 정의한다.

- CPU, 메모리 같은 리소스와 가용성 요구사항을 바탕으로, 클러스터 전체에 컨테이너를 배치하는 **스케줄러**도 갖추고 있다.

컨테이너 장애 발생 시 자동으로 복구되는 기능을 가지고 있어서, 어플리케이션 실행에 필요한 수 만큼의 컨테이너를 항상 확보할 수 있다.

Amazon EC2의 부하분산 기능인 Elastic Load Balancing(ELB)를 사용해 트래픽을 컨테이너 전체로 분산시킬 수 있다.

어플리케이션 전개는, 이미지를 새로운 버전으로 업로드하면 구 버전 컨테이너를 정지하고 새로운 컨테이너를 자동 시작하는 방식으로 이루어진다.

AWS의 감시 서비스인 Amazon CloudWatch와 연계해, CPU나 메모리 사용을 감시할 수 있다.

#### Azure Container Service (AKS)

MS Azure의 컨테이너 매니지드 서비스로, 컨테이너 오케스트레이션 툴로 Kubernetes를 지원하고 있다.

Azure 가상 머신을 사용해 클러스터를 구성한다.

Docker 레지스트리 서비스로 Azure Container Registry를 제공한다.

Azure Batch Shipyard라는 **과학기술계산** 등의 용도로 이용되는, 대규모 분산 배치 처리 기반의 일부로도 Docker를 이용한다.

#### Google Kubernetes Engine (GKE)

GCP의 컨테이너 매니지드 서비스이다.

> #### 과학기술계산을 위한 분산 배치 처리 실행 서비스 Amazon Batch
> 
> AWS는 풀매니지드형 **분산 배치 처리 실행 서비스**인 Amazon Batch를 제공한다.
> 
> 이는 대규모 구조 해석, 유체 해석 같이 지금껏 슈퍼컴퓨터로 수행하던 과학기술계산을 **클라우드 상 리소스를 사용해** 수행하기 위한 서비스이다.
> 
> 대량의 배치 잡을 실행하기 위해 클러스터 관리 기능, 잡 스케줄러 등 기능을 보유하고 있고, 기본적으로 Amazon ECS이므로 잡이 **컨테이너 상에서 실행**되는 것이 큰 특징이다.

### Google Cloud Platform의 컨테이너 관련 서비스

GCP는 구글이 제공하는 퍼블릭 클라우드 서비스.

- 가상 머신을 제공하는 Google Compute Engine

- 대규모 데이터를 다루는 BigQuery 등이 있다.

가장 큰 특징은, 구글 자사 서비스를 제공하기 위해 구축된 기반과 같은 것을 이용할 수 있다는 점.

- 컨테이너 가동 실적이 풍부하고, 세계 최대 규모의 네트워크를 가지고 있음.

- 컨테이너 기반 웹 어플리케이션 실행 기반 구축 서비스, 대규모 데이터를 분산 환경에서 사용해 머신러닝하는 서비스에 충실함

#### Google Container Builder

Dockerfile을 바탕으로 Docker 이미지를 GCP 상에서 작성하기 위한 커맨드 툴.

리포지토리에 저장된 Dockerfile로부터 이미지를 빌드하고 레지스트리에 자동으로 업로드한다.

해당 이미지 저장 위치는, GCP의 오브젝트 스토리지 서비스인 Google Cloud Storage를 지정해 업로드할 수 있다.

- 스토리지 액세스를 제한할 수 있어, 프라이빗한 환경 조성이 가능하다.

#### Google Kubernetes Engine

Docker 컨테이너를 관리하는 풀매니지드 서비스.

사용자 정의 인프라 요구사항을 바탕으로 컨테이너를 **클러스터에 스케줄링하여 자동으로 관리**한다.

오픈소스 컨테이너 오케스트레이션 툴인 Kubernetes를 이용하고 있으며, 어플리케이션 요구 변화에 맞춰 클러스터 리소스나 컨테이너 클러스터의 스케일링이 가능하다.

#### Google Container Registry

Docker 이미지를 GCP 제품 안에서 관리할 수 있는 프라이빗 레지스트리 서비스.

전용 API를 사용해, Docker 이미지를 업로드 및 다운로드 할 수 있다.

저장 위치는 GCP가 제공하는 오브젝트 스토리지 서비스.

이미지의 아카이브는 Cloud Storage Nearline 버킷에 저장할 수 있다.

---

## Kubernetes의 개요

여러 개의 호스트를 하나로 묶어 Docker를 이용하기 위한 오케스트레이션 툴로, 분산 환경에서 **마치 한 대의 컴퓨터처럼** 투과적으로 컨테이너에 엑세스할 수 있다.

급증하는 부하에 대해 오토스케일하는 장치나, 여러 컨테이너를 효율적으로 통합 관리하는 장치도 있다.

주요 기능으로,

- 여러 서버들에서의 컨테이너 관리

- 컨테이너 간 네트워크 관리

- 컨테이너의 부하분산

- 컨테이너의 감시

- 무정지 업데이트

### Kubernetes의 서버 구성

Kubernetes를 사용하는 실행 환경에서는 여러 다른 역할을 가진 서버들이 작동한다.

분산된 서버들이 협력하여 각각 처리를 수행하는데, 이러한 덩어리를 **Kubernetes 클러스터**라고 한다.

#### 마스터 서버 (Kubernetes Master)

클러스터 안의 컨테이너를 조작하기 위한 서버.

`kubect1` 명령을 사용해 클러스터를 구성하거나 리소스를 조작할 때, 마스터 서버가 커맨드를 받아 처리를 수행한다.

클러스터 안에 노드의 리소스 이용 상황을 확인하고, 컨테이너를 시작할 노드를 자동으로 선택해준다.

- 마스터 서버가 여러 대로 분산 구성된 **노드**를 모아서 관리함으로써, 마치 한 대의 서버인 것처럼 행동할 수 있다.

#### 백엔드 데이터베이스 (etcd)

**분산 키 밸류 스토어**(KVS)를 사용하여, **클러스터의 구성 정보**를 관리한다.

마스터 서버와 마찬가지로 **다중화**를 검토할 필요가 있다.

#### 노드 (Node)

실제로 Docker 컨테이너를 작동시키는 서버.

노드를 여러 개 마련함으로써 클러스터를 구성하고, 노드들의 관리는 마스터 서버가 한다.

노드의 개수는 시스템 규모와 부하에 따라 달라진다.

- 클라우드의 경우, **가상 머신의 인스턴스**가 노드가 된다.

### 어플리케이션 구성 관리 (Pod, ReplicaSet, Deployment)

Kubernetes를 사용하여 Docker 컨테이너를 다루기 위해 이해해야 할 기본 개념들.

#### Pod (포드)

Kubernetes에서는 여러 컨테이너를 모아서 Pod로 관리한다.

Pod는 **어플리케이션의 전개 단위**가 되고, Pod 단위로 컨테이너 시작/정지 같은 조작을 수행하게 된다.

웹 서버 - 프록시 서버 같이 관련되는 기능을 묶어서 Pod로 관리해야 한다.

즉, Pod가 여러 노드에 걸치는 경우는 없고, **반드시 동일한 노드 상에 동시에 전개**된다.

- Pod 안 여러 컨테이너가 가상 NIC를 **공유**하고 있기 때문에, 컨테이너 간 localhost 통신도 가능하다.

- 공유 디렉토리를 통해 로그 정보를 공유할 수도 있다.

보통 노드 안에 여러 개의 Pod가 배치된다.

#### ReplicaSet (리플리카 셋)

Kubernetes 클러스터 상에서 **미리 지정된 Pod를 작성하여 실행시켜 두는** 장치.

즉, **클러스터 상에 정해진 수의 Pod는 반드시 실행시켜 둔다**는 것.

- 실행 중인 Pod를 감시하여, 장애가 발생한 Pod가 생기면 삭제하고 새로운 Pod를 실행시킨다.

- 결과적으로 필요한 수 만큼의 Pod는 클라우드 안에 항상 존재하게 된다.
  
  - 클라우드 안에 Pod를 얼마나 실행시켜 둘지를 **리플리카 수**라고 한다.

Pod 수를 동적으로 변경하여, **오토스케일** 구현도 가능하다.

#### Deployment (디플로이먼트, 전개)

Pod와 ReplicaSet을 모은 것으로, **ReplicaSet의 이력을 관리**하는 것.

**정의된 리플리카의 수를 유지하는 것**이 ReplicaSet이고, **ReplicaSet의 작성이나 갱신을 정의하는 것**이 Deployment라고 보면 된다.

- ReplicaSet의 탬플릿을 가지고, 거기에서 Pod 구성을 정의하여 **해당 탬플릿을 따르는 ReplicaSet을 만든다.**

- 이력 관리가 가능하여, 이미지의 버전업이 필요할 때 무중단 업데이트가 가능하고, 롤백도 가능하다.

#### 그 외

- 노드 별로 감시 에이전트 같이 **특정 Pod를 반드시 배치**할 때 이용하는 **DaemonSet**

- 웹 서버 같은 상주 서비스가 아닌, 프로그램의 시작부터 종료까지로 완료되는 프로그램을 Pod에서 실행시키는 **Jobs**

- Linux의 cron 같이 Pod를 실행시킬 타이밍을 지정하는 **CronJob**

### 네트워크 관리 (Service)

Kubernetes 클러스터 안에서 실행되는 Pod에 대해, **외부로부터 엑세스하고자 할 때** 서비스를 정의한다.

서비스는, **Kubernetes의 네트워크를 관리**하는 것.

- 그 중 **Load Balancer**는, 서비스에 대응하는 IP 주소 + 포트 번호로 엑세스할 때 여러 Pod에 대해 **레이어 4 레벨의 부하분산**이 일어나게 한다.

서비스에 의해 할당되는 IP 주소에는 Cluster IP와 External IP가 있다.

- **Cluster IP**는 **클러스터 안 Pod끼리 통신**하기 위한 프라이빗 IP 주소이다.
  
  - 클러스터 안의 Pod가 Cluster IP로 보내는 패킷은, **노드 상의 Proxy 데몬이 받아** 수신 Pod로 전송된다.

- **External IP**는 **외부 클라이언트가 연결**하기 위한 퍼블릭 IP 주소이다.

Pod를 새로 실행할 때, 기존 서비스의 IP 주소와 포트 번호를 환경변수로 참조할 수 있다.

> #### Ingress를 사용한 네트워크 제어
> 
> Kubernetes에 서비스 외에도 Pod에 대한 통신을 제어하는 기능으로 Ingress가 있다.
> 
> Ingress는, 서비스와 연결되어 **통신 내용을 프록시**한다.
> 
> - Kubernetes가 작동하는 환경에 따라 내용이 다르다.
> 
> - GCP의 경우 HTTP Load Balancer를 사용. 레이어 7에서 작동하면서 세세한 네트워크 제어가 가능하다.

### Label을 사용한 리소스 식별

Kubernetes에서는 리소스 식별을 위해 내부에서 자동으로 랜덤한 이름을 부여한다.

관리 용이성을 위해, 알기 쉬운 Label을 붙여 관리할 수도 있다.

Label은 Key-Value형의 임의의 문자열로, 이를 식별자로 하여 리소스를 일괄 처리할 수 있다.

- 버전 업데이트가 필요할 시 `app:v1.0` 이런 식으로 Label을 설정하고,

- 서비스 정의에서 **Selector**를 해당 버전으로 지정하면 그 라벨이 붙은 Pod로만 리퀘스트가 전송된다.
  
  - Selector는 Label이 붙은 리소스를 참조할 때 사용한다.

하나의 리소스에도 **여러 개의 Label을 설정**할 수 있으므로, 역할 별로 이름을 붙이거나 관련 있는 Pod 별로 유연하게 관리할 수 있다.

- 대규모 웹 시스템에서는 Pod가 많고 버전도 다양하기 때문에, Label을 잘 붙여서 **논리적인 그룹핑**이 필요하다.

Label은 Kubernetes의 정의 파일인 매니페스트 파일을 참조할 때도 사용된다.

### Kubernetes의 구조

기본적으로 마스터, 데이터 스토어, 노드가 서로 협력하면서 컨테이너 실행 환경을 관리하는데, 그 안에서 몇 가지 **컴포넌트**가 동작한다.

#### 1. 마스터 (Master)

##### API Server

Kubernetes의 **리소스 정보를 관리**하기 위한, **프론트엔드 REST API**이다.

각 컴포넌트로부터 리소스 정보를 받아, **데이터 스토어**(etcd)에 저장한다.

- 각 컴포넌트는 역시 API를 통해 etcd의 정보에 엑세스하게 된다.

프로그래머가 API Server에 엑세스하려면 웹의 GUI 툴이나 `kubectl` 명령을 사용한다.

어플리케이션 안에서도 API Server 호출이 가능하고, 자체적으로 인증 및 인가 기능도 가진다.

##### Scheduler

**Pod를 어떤 노드에서 작동시킬지 제어하는 백엔드 컴포넌트**이다.

노드에 할당되어 있지 않은 Pod에 대해, Kubernetes **클러스터의 상태를 확인하고 빈 영역을 가진 노드를 찾아 Pod를 실행**시킨다.

##### Controller Manager

Kubernetes **클러스터의 상태를 항상 감시하는 백엔드 컴포넌트**이다.

정의 파일에서 정의한 것, 실제 노드나 컨테이너가 움직이는 상태 등을 모아 관리한다.

#### 2. 데이터 스토어 (etcd)

Kubernetes 클러스터 구성을 유지 관리하는 KVS.

어떤 Pod를 어떻게 배치할 지 등의 구성 정보를 갖고 있으며, API Server가 참조한다.

#### 3. 노드 (Node)

##### kubelet

노드에서는 kubelet이라는 **에이전트**가 작동한다.

Pod의 정의 파일에 따라, **Docker 컨테이너를 실행하거나 스토리지를 마운트**하는 기능을 가진다.

**노드의 스테이터스를 정기적으로 감시**하고 변경이 있을 시 **API Server에 통지**할 수도 있다.

#### 매니페스트 파일 (manifest)

Kubernetes에서 클러스터 구성 정보를 YAML이나 JSON 형식 정의 파일로 관리하는 것.

선언 기반으로 구성을 관리할 수 있고, Jenkins 같은 소프트웨어 버전 관리 시스템과 연계가 가능하다.

> #### Stateful과 Stateless 어플리케이션
> 
> ##### Stateful 어플리케이션
> 
> **세션이 종료될 때까지, 클라이언트의 세션 정보를 저장하는 네트워크 프로토콜**
> 
> - **예제**
>   - **TCP 프로토콜**
>     - TCP는 클라이언트와 서버간 3-way handshaking(연결 확정, 데이터 전송, 연결 종결)로 이루어져 있다.
>     - 클라이언트와 서버간 연결 확정 후, 데이터를 전송하고, 데이터 전송이 끝나면 연결이 종결된다.
>   - **온라인 뱅킹**
>     - 은행(서버)은 고객(클라이언트)의 인증 정보(세션 상태)와 결제 내역(세션 정보)을 가지고 있다.
> - **장점**
>   - 서버는 클라이언트의 세션 정보를 저장하므로, 갑자기 통신이 중단되더라도 중단된 곳부터 다시 시작할 수 있다.
> - **단점**
>   - 확장성이 좋지 않다.
>     - 클라이언트의 세션 정보가 새로 scale out 된 서버에 저장 되어 있지 않다.
>     - 따라서, scale out 시, 클라이언트의 세션 정보를 새로운 서버에 옮겨주는 등의 부수적인 관리가 요구되므로, 확장성이 좋지 않다.
> 
> ##### Stateless 어플리케이션
> 
> **서버가 클라이언트의 세션 상태 및 세션 정보를 저장하지 않는 네트워크 프로토콜**
> 
> - 즉, 요청에 대한 응답만 처리하는 방식
> - 각 통신은 선행되거나 후속으로 따라오는 통신과 관련이 없다.
> - 클라이언트가 송신하려 했던 모든 데이터가 서버쪽에 수신 되었는지 확인하지 않는다.
> 
> - **예제**
>   - **UDP 프로토콜**
>     - UDP는 서버가 클라이언트의 세션 상태 및 세션 정보 없이, 요청에 대한 응답만을 수행하는 네트워크 프로토콜.
>   - **온라인 검색(검색창에 질문을 입력하고 엔터키를 누르는 형식)**
>     - 검색창에 질문을 입력하다가 요청이 중단되어도, 다시 검색하면 된다.
> - **장점**
>   - 확장성이 좋다.
>     - 서버가 클라이언트의 세션 상태 및 세션 정보를 저장하지 않기 때문에, 확정성이 좋다.
> - **단점**
>   - 서버가 세션 상태 및 세션 정보를 저장하지 않기 때문에, 클라이언트 측에서 송신할 데이터의 양이 많아진다.

> #### 컨테이너에서의 영구 데이터 관리와 클라우드의 데이터 관리 서비스
> 
> Kubernetes의 **StatefulSets**를 사용해, **Stateful 어플리케이션**을 지원할 수 있다.
> 
> - StatefulSets는 Pod마다 고유 ID와 상태를 가질 수 있어, 웹 서버와 DB가 연동되는 어플리케이션에서 사용해보면 좋다.
> 
> 하지만 Docker는 **Stateless** 어플리케이션에 보다 적합한 툴로, 영구 데이터 관리에는 취약점이 있다.
> 
> - 영구 데이터를 적절하게 관리하기 위해 백업, 리스토어 장치, 데이터량 증대에 대한 스케일 아웃, 보안 대책, 운용 정비 등 검토 사항이 많다. 
> 
> - 이 때 클라우드에서 제공되는 **데이터 관리 서비스**를 잘 활용하면 좋다.

---

## GCP를 사용한 Docker 어플리케이션 개발


