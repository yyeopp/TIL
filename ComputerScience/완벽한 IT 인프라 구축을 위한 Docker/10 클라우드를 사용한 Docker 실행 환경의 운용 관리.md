# Chapter 10: 클라우드를 사용한 Docker 실행 환경의 운용 관리

---

시스템 릴리즈 후에도, 리소스 감시, 데이터 백업, 장애 감시, 복구 대응 등 **시스템 운용**이 필수적이다.

퍼블릭 클라우드를 사용해 구축한 Docker 시스템을 안정 가동시키기 위해서는 시스템 운용 기초 지식과 Kubernetes 클러스터 운용 방법에 대한 지식이 있어야 한다.

---

## 시스템 운용의 기초 지식

### 가용성 관리

**가용성**은 시스템을 계속해서 가동시킬 수 있는 능력.

가용성 높은 시스템을 만들기 위한 대표적인 기술로 **다중화**가 있다.

- 다중화란, 만일 장애가 발생해도 시슽메 전체가 정지되지 않도록 하는 기술 요소다.

#### 콜드 스탠바이 방식

구성이나 설정이 똑같은 **백업 기기**를 마련해 두고, 실제 환경 근처에 대비시켜 둔다.

실제 환경에 장애가 발생하면 백업 기기에 전원을 넣고 **기기를 통째로 교체**하는 방식.

- 전원을 꺼 둔 채로 대기시키기 때문에 **콜드** 스탠바이다.

- 소규모 온프레미스 환경에서 자주 채택된다.

중요한 것은, 실제 환경 기기와 백업 기기가 **완전히 똑같이 설정**되어 있어야 한다는 점.

단일 기기 교환 뿐만 아니러 서버와 네트워크 같은 시스템까지 통째로 교환하기도 한다.

#### 핫 스탠바이 방식

**동일한 구성**의 서버를 2대 동시에 가동시키고, 메인 서버에 장애 발생 시 대기 중인 다른 서버가 대신 처리를 이어받는 구성이다.

둘다 가동 중이므로, 데이터 갱신이 실시간으로 일어나고, 장애 발생 시 전환 시간도 짧다.

장애가 발생한 서버나 기기를 시스템에서 자동으로 떼어내고 예비 기기로 전환하는 것을 **페일오버**(failover)라고 한다.

- 페일오버에는 액티브  기기의 **서버 IP 주소를 이어받는 것**과 **서버 버전 정보를 이어받는 것**이 있다.

#### 헬스 체크

장애 시 신속하게 전환하기 위해, **액티브 기기의 장애 발생 여부를 감지하는 장치**이다.

서버에 일정 간격으로 응답 요청을 보내, 정상적인 응답이 돌아오는지 여부로 판단한다.

아래와 같은 종류가 있는데, 레이어가 높을수록 정확한 헬스 체크가 가능하나, 서버 부하가 그만큼 높아진다.

##### ICMP 감시 (레이어 3)

Ping 등의 응답을 확인한다.

##### 포트 감시 (레이어 4)

웹 서비스의 경우, 80번 포트로부터 응답이 있는지 확인한다.

##### 서비스 감시 (레이어 7)

HTTP 통신을 확인하는 경우, 특정 페이지가 올바르게 표시되는지 확인한다.

#### 로드 밸런싱 (load balancing)

**다중화** 구성 이후 대기 서버를 보유만 하면, 시스템 가용성은 향상되지만 **낭비**의 측면이 있다.

로드 밸런싱은 시스템 가용성 향상과 **처리 속도 향상**을 동시에 수행할 수 있다.

- 서버의 처리를 여러 기기로 나눔으로써 부하 집중을 막고, 낭비를 줄이는 것.

- 웹 어플리케이션 서버 같이 **트래픽이 집중되는 곳**에 주로 이용된다.

**로드 밸런서**라는 전용 기기를 사용해, 알고리즘에 기초하여 요청 처리를 분산시키게 된다.

- 요청을 **균등하게 할당**하는 **라운드 로빈** 방식이나

- 요청의 내용에 따라 할당처를 정하는 알고리즘 등이 있다.

로드 밸런싱 과정에서 **헬스 체크**를 통해 장애가 있는 서버에는 요청을 할당하지 않는다.

다만, 로드 밸런서 자신 또한 **단일 장애점**(SPOF)이기 때문에 이것도 다중화해야 시스템의 가용성을 향상시킬 수 있다.

- 단일 장애점은, **한 장소에 장애가 발생하면 시스템 전체를 이용할 수 없게 되는 부분**.

주요 메이저 퍼블릭 클라우드들은 로드 밸런서 기능을 서비스로 제공하고 있다.

- GCP의 경우 Cloud Load Balancing 서비스를 제공한다.

- ㅇ러 지역이나 영역을 걸쳐 로드 밸런싱 함으로써, 다중화를 구현한다.

> #### 재해 복구 시스템
> 
> 재해로부터 피해를 입은 시스템을 복구 및 수리하는 것.
> 
> 시스템 자체를 재해로부터 보호하고, 망가져도 효율적으로 복구하기 위해 예비 기기를 두거나 복구 체제를 미리 정해두는 것을 포함한다.
> 
> 대규모 시스템을 온프레미스 환경에서 운용할 경우, 보통 다른 원격지에 백업 사이트를 두고 운용 관리를 한다.
> 
> - 데이터센터가 이중이 되므로, **비용이 막대**하다.
> 
> - 그 정도 여유가 없다면 백업을 정기적으로 하여 다른 지역 영업소에 보관하는 정도가 가능하다.
> 
> - 혹은, 아예 대책 자체를 세우지 않고 방관하는 경우도 있다.
> 
> Docker를 사용하는 시스템의 경우 Dockerfile로 실행 환경을 구축할 수 있으므로, 클라우드 서비스를 잘 이용해 재해 복구 시스템을 검토하는 게 좋을 것.
> 
> - 퍼블릭 클라우드의 로드 밸런싱 서비스를 사용하면 **전 세계로 부하가 분산**되는데, 이런 경우 재해 복구 시스템 마련 자체가 불필요하다.
> 
> 재해 복구 시스템 구축 시 두 가지를 정할 필요가 있다.
> 
> ##### RTO (Recovery Time Objective)
> 
> 재해 등으로 시스템이 정지된 이후, 서비스 복구까지 필요한 **경과 시간**이다.
> 
> **목표 복구 시간**이라고 하면 된다.
> 
> ##### RPO (Recovery Point Objective)
> 
> 재해 등으로 시스테밍 정지되었을 때, 어떤 시점까지 거슬러 올라가서 데이터를 복구시킬지에 대한 지표이다.
> 
> 짧을수록 손실되는 데이터가 줄어들어 시스템 가용성은 높아지지만, 비용도 높아진다.

### 수용성 (Capacity) 관리

시스템이 제공하는 **서비스의 수요**를 예측, 감시, 평가하고 이를 만족시키기 위해 필요한 최적의 **시스템 리소스**를 제공할 수 있도록 관리하는 것.

- 기본적으로 수요에는 변동이 있으므로, **필요한 양 만큼만 제공하는 것이** 바람직한 시스템이다.

온프레미스 환경이라면 수요를 사전에 가늠하여 시스템 리소스를 마련해야 하는데, 이는 상당히 어려운 일이였다.

- 특히 B2C에서 **스파이크 액세스**(급격한 부하 증가)가 발생하면 서비스가 정지될 우려가 있다.

클라우드 환경이라면, 이용한 리소스의 **양과 시간에 따라 요금이 부과**되므로, 필요한 리소스를 시스템 부하에 따라 **동적으로 변경**할 수 있는 장점이 있다.

시스템 운용 시 지속적으로 발생하여, 프로그램이 종료되어도 스토리지에 저장되는 데이터를 **영구 데이터**라고 하는데, 시스템 가동 시간에 따라 축적 및 변경되는 특징이 있다.

- 스토리지 저장 영역에도 한계가 있고, 스토리지 장애도 가능한 상황이믈 영구 데이터를 적절히 관리할 필요가 있다.

영구 데이터 관리에서 중요한 게 데이터 백업과 복구이고, 기밀 정보에 대한 보안 대책도 필요하다.

- 클라우드의 경우 장기간의 백업에 적합한 스토리지 서비스가 제공되고 있고,

- 심지어 재해에 대비해 다른 리전에 보관하는 것도 가능하다.

시스템 가동 중 발생하는 **로그**에 대해 분산 환경에서 **전용 로그 수집 서버 또는 로그 집약 서비스**를 사용하는 것이 일반적이다.

- 시스템에 따라서는 보안 감시 로그에 대해 장기 보관이 의무화되기도 한다.

- Unix 계열이라면 syslogd라는 데몬을 사용해 커널이나 어플리케이션의 로그를 관리한다.

- 로그 수집용 미들웨어로는 Fluentd가 유명하다.

> #### SLA
> 
> 서비스 레벨 관리.
> 
> 시스템 제공자와 이용자 사이에 미리 **서비스 레벨**을 규정하고, 이를 유지 관리하는 것.
> 
> 미리 규정하는 서비스 레벨을 **SLA**라고 한다.

### 시스템 감시

안정적인 시스템 가동을 위해서는, 시스템을 구성하는 서버들과 네트워크 기기의 상태를 적절히 감시하고 관리할 필요가 있다.

보통 **시스템 감시 전용 툴**을 사용하는데, 

- 시스템의 감시 대상이 서버나 기기의 상태를 감시해 **미리 설정한 한계 값을 초과한 경우** 정해진 액션을 실행한다.

- 서버 상태를 가시화하는 GUI를 제공하거나,

- 시스템 장애 시 관리자에게 알림을 송신하는 기능을 제공한다.

클라우드의 경우 가상 인스턴스와 스토리지를 감시하는 전용 서비스를 마련하고 있다.

하이브리드 클라우드 환경인 경우, 별도의 SaaS가 필요할 수 있다.

시스템 감시의 종류는 아래와 같다.

#### 머신의 활동 감시

시스템을 구성하는 머신이 문제없이 가동되고 있는지 감시하고, 장애 여부를 확인한다.

클라우드를 사용하는 경우 클라우드 서비스 자체의 장애 여부를 확인할 필요도 있다.

#### 서비스의 가동 감시

서비스가 문제없이 가동되고 있는지 감시한다.

장애 발생 시 로그를 확인하고, 프로세스를 재시작하는 등 대처한다.

#### 서버/네트워크의 리소스 감시

**수용성 관리**의 일환으로 리소스 사용량, 네트워크 대역을 감시하고 **병목 현상**에 대비한다.

중장기적 관점에서 시스템 부하의 증감을 감시하여, 기기나 회선 증강을 검토한다.

클라우드 시스템의 경우 이 부분 운용 코스트가 크게 감소한다.

#### 잡 감시

업무 시스템의 **배치 처리**를 적절히 감시한다.

#### 장애 대응

오류의 원인을 제거하여 시스템을 정상 상태로 되돌리는 것.

일차 대응으로, 오류의 원인과 복구 방법을 알고 있다면 미리 정해진 절차를 밟아 복구 대책을 수행한다.

- 서비스 재시작, 장애 기기 분리 및 교체 등.

- 데이터 손실의 경우 백업이나 저널 파일을 바탕으로 복구한다.

- 원인이 불분명하다면 로그를 취득하면서, 엔드 유저에게 영향이 없도록 오류가 발생한 부분을 분리한다.

일차 대응 이후, 엔드 유저의 정상 이용을 위해 **장애 원인**을 조사한다.

- 보통 **로그 파일의 해석**이 매우 중요하다.

- 분산 환경의 경우 단일 노드의 로그만 봐서는 규명이 어렵고, 관련 노드와 네트워크 기기의 로그를 함께 조사한다.

- 장애 발생 시기의 **리소스 상황**도 볼 필요가 있다.

마지막으로, 규명된 장애 원인을 바탕으로 재발 방지를 위해 **영구 대책**을 세운다.

- 리소스 부족이라면 리소스 증감 감시를 강화하고,

- 휴먼 에러라면 요원 배치, 절차 보완 등이 가능하다.

> #### 퍼포먼스 튜닝
> 
> 서비스 릴리즈 이후, 서버 감시 결과를 바탕으로 퍼포먼스 튜닝이 이루어진다.
> 
> 이는 시스템 처리 중 **병목**이 일어나는 장소를 찾고 이를 최적화하기 위해 각종 파라미터를 조정하는 작업이다.
> 
> 퍼포먼스 튜닝 시 중요한 것은 **처리 속도의 계측**이다. **어디에서 병목이 있는지** 판단하는 핵심 지표이기 때문.
> 
> - 병목 위치를 특정해야, 해당 처리 지연을 없애기 위한 대책을 세울 수 있다.
> 
> 병목이 인프라 레이어가 아닌 어플리케이션 레이어에서 발생하는 경우도 있으니 주의해야 한다.

---

## GKE를 사용한 Docker 실행 환경의 운용
