# CAS - 동기화와 원자적 연산

---

## 원자적 연산

### 개요

**원자적 연산**은 해당 연산이 더 이상 나눌 수 없는 단위로 수행된다는 것을 의미한다.

- 중단되지 않고,

- 다른 연산과 간섭 없이 완전히 실행되거나 전혀 실행되지 않는다.

즉, **멀티스레드 환경에서 다른 스레드의 간섭 없이 안전하게 처리되는 연산**을 뜻한다.

#### 예시

```java
volatile int i = 0;
i = 1;         // 원자적 연산이 맞음
i = i + 1;     // 원자적 연산이 아님
```

- `i = i + 1` 은 `i`라는 필드에 대한 접근이 **실제로는 총 2번** 발생한다.

- `i = 1`의 경우 필드에 대한 접근이 단 1번 발생한다.

원자적 연산의 경우, 멀티스레드 환경에서 아무런 문제가 발생하지 않는다.

원자적 연산이 아닌 경우, `synchronized` 블럭이나 `Lock` 등을 사용하여 **안전한 임계 영역**을 만들 필요가 있다.

### AtomicInteger

자바는 멀티스레드 상황에서 안전하게 증가 연산을 수행할 수 있는 `AtomicInteger` 클래스를 제공한다.

- 이름 그대로 원자적인 Integer 이다.

```java
    AtomicInteger atomicInteger = new AtomicInteger(0);
    @Override
    public void increment() {
        atomicInteger.incrementAndGet();
    }

    @Override
    public int get() {
        return atomicInteger.get();
    }
```

- `incrementAndGet` 같은 메서드를 사용하면, 마치 `synchronized` 블럭을 적용한 것과 같이 멀티스레드 환경에서 스레드 간섭 없이 증감 연산이 안전하게 수행될 수 있다.

`AtomicInteger` 뿐만 아니라 `Long, Boolean` 등 다양한 `Atomic` 클래스가 존재하니, 필요에 따라 활용하면 된다.

### 성능 검증

예제로, 아래 4개의 코드를 작성했다.

- 아무 장치 없이 `int` 필드에 대한 증가 연산

- `volatil` 부여한 뒤 증가 연산

- `synchronized` 블록을 적용한 증가 연산

- `AtomicInteger` 필드에 대한 증가 연산

일단 정상 작동 여부를 따져보면,

- 1, 2는 비정상 작동

- 3, 4는 정상 작동하며

성능을 검증했을 때

- 1 >>>> 2 > 4 >>> 3 

주목할 점은 `synchronized`와 `AtomicInteger` 간의 성능 차이이다.

- 둘다 멀티스레드 환경에서 대응하여, 원하는 연산을 정확히 수행하고 있지만

- `AtomicInteger` 쪽이 대략 3배는 빠르다.

이러한 차이를 만들어내는 이유는,

`AtomicInteger`의 경우 **락을 사용하지 않고 원자적 연산을 만들어냈기 때문**이다.

---

## CAS 연산

### 락 기반 방식의 문제점

`synchronized` 블록을 사용할 시, 자바는 **락**을 사용하여 임계영역을 보호한다.

- 멀티스레드 환경에서 스레드 블록 상태를 유발할 수밖에 없고,

- 락을 획득하고 해제하는 것 자체도 오버헤드가 있다.

즉, 락을 사용할 시 **직관적이고 안전하지만** **상대적으로 무거울 수밖에 없다.**

### CAS

이러한 문제를 해결하기 위해, **락을 걸지 않고도 원자적인 연산을 수행하는 방법이 필요**했다.

- CAS (Compare-And-Swap, Compare-And-Set)

락을 사용하지 않기 때문에 **락 프리** 기법이라 한다.

락을 완전히 대체할 수는 없고, **작은 단위의 일부 영역**에 사용할 수 있다.

#### compareAndSet()

`AtomicInteger`가 가지고 있는 값을 특정한 값과 비교하여, 동일하면 다른 값으로 변경하라는 극히 단순한 메서드다.

근데 중요한 건 해당 연산이 **CAS**에 해당한다는 점이다.

- 기계적으로 작동 기작을 따져봤을 때 2개의 연산임에도

- 실제로는 **CPU가 1개의 연산, CAS로 인지하고 있다.**

### CPU 하드웨어의 지원

CAS 연산은, 실제 원자적이지 않은 두 개의 연산을 **CPU 하드웨어 차원에서 특별히 하나의 원자적인 연산으로 묶어서 제공하는** 기능이다.

- 소프트웨어가 아닌, **하드웨어**가 제공하는 기능으로 대부분의 현대 CPU들은 CAS 연산을 위한 명령어를 제공해주고 있다.

CPU가 **실제로 2가지 작업**을 수행하는 것은 사실이나, 

CPU에게 **원자적 연산을 하라는 오더가 들어갔기 때문에** CPU 수준에서 해당 **메모리 값**에 대한 **다른 스레드의 변경을 차단**해주는 것이다.

- 어찌 보면 CPU 수준에서 락을 걸었다고 볼 수도 있는데,

- 프로그램에서 락을 거는 것과 달리 하드웨어적인 부분이라 **성능에 거의 영향을 주지 않게 된다**.

- 그래서 **락**이라고 취급하지도 않는다.

### CAS 연산

```java
    private static int incrementAndGet(AtomicInteger atomicInteger) {
        int getValue;
        boolean result;
        do {
            getValue = atomicInteger.get();
            sleep(100);
            log("getValue : " + getValue);
            result =  atomicInteger.compareAndSet(getValue, getValue + 1);
            log("result : " + result);
        } while (!result);
        return getValue + 1;
    }
```

- `AtomicInteger`는 **락을 사용하지 않으면서도 증감 연산에 대해 원자적으로 처리할 수 있다.**

- 그 원리에 대해 정확히 파악할 필요가 있는데, 대표적인 메서드인 `incrementAndGet` 메서드는 실제로 위 로직으로 동작한다.

- 간략히 정리하면 **연산 수행 중 다른 스레드에 의해 `AtomicInteger` 값이 변경될 시, 연산 처리를 중지하고 루프를 돌며 재시도하는** 방법이다.

- 그리고 이 로직에서 가장 핵심은 `compareAndSet`이다.

- CPU가 제공하는 CAS 연산을 활용하여, **안전한 증감연산을 수행할 수 있도록 알고리즘을 구성**했다고 이해할 수 있다.

#### CAS 연산 정리

- 현재 변수의 값을 읽어와서 **지역변수**에 저장한다.

- 변수의 값을 1 증가시키고자 `compareAndSet` 메서드를 사용할 때, 자연스럽게 **그 시점 변수의 값이 지역변수 값과 동일한지**, 즉 **그 사이에 다른 스레드에 의해 값이 변질되지 않았는지**를 확인한다.
  
  - `compareAndSet`이 실패하면 값이 변질된 것이므로 `while`로직에 의해 처음부터 다시 시도하고,
  
  - 성공하면 그대로 1 증가한 값이 변수에 저장된다.

#### 스레드의 충돌과 성능

두 스레드가 동시에 실행되며 문제가 발생하는 상황을 **스레드 충돌**이라고 표현한다.

CAS 연산은 충돌이 발생할 때 **반복해서 다시 시도하므로** 결과적으로 **락 없이 데이터를 안전하게 변경**할 수 있다.

즉, CAS를 사용하는 방식은 **충돌이 드물게 발생할수록 높은 성능**을 발휘할 수 있다.

하지만 충돌이 빈번하게 발생하는 환경에서는 CAS가 자주 실패하고 재시도하기 때문에, CPU 자원을 지속적으로 소모하여 성능 저하가 발생할 수 있다.

### CAS와 락 방식의 비교

#### 락(Lock) 방식

**비관적**(pessimistic)인 접근법

- 스레드 충돌을 처음부터 상정하고 시작함

데이터에 접근하기 전에 **항상** 락을 획득하고 다른 스레드의 접근을 막음

#### CAS(Compare-And-Swap) 방식

**낙관적**(optimistic)인 접근법

- 스레드 충돌이 날 수도 있기는 한데, **없을 수도 있다고** 기대하면서 시작함

락을 사용하지 않고 데이터에 접근하고,

**충돌이 발생하면 그 때 재시도하여 failover 처리**

#### 어떤 방식이 좋은가?

이론적으로 **충돌이 많이 발생하는 경우 Lock, 많이 없는 경우 CAS**라고 할 수 있는데,

대부분의 CPU 연산은 **정말 빠르게 처리되기 때문에 충돌이 자주 발생하지 않는다**.

즉, 대체로 CAS가 좋다.

---

## CAS 락 구현

CAS는 단순 연산 뿐만 아니라 **락을 구현**하는 데에 사용할 수도 있다.

```java
    private final AtomicBoolean lock = new AtomicBoolean(false);

    public void lock() {
        log("락 획득 시도");
        while (!lock.compareAndSet(false, true)) {
            log("락 획득 실패 - 스핀 대기");
        }
        log("락 획득 완료");
    }

    public void unlock() {
        lock.set(false);
        log("락 반납 완료");
    }
```

- 위와 같이, `lock` 같은 `boolean` 변수로 애플리케이션 로직 수준에서 멀티스레드를 통제한다고 할 때,

- `AtomicBoolean`과 `compareAndSet`을 활용하면 **락 없이 CAS 연산으로** 목적을 달성할 수 없다.

`AtomicBoolean` 을 사용하지 않고 위 로직을 구현한다고 하면,

- `lock` 변수가 `false` 인지 확인

- `false` 면 `true`변경

- 이렇게 2가지 과정을 거쳐야하기 때문에 멀티스레드 통제가 정확히 이루어질 수 없다.

CAS 연산을 적용하여,

- **락이 잡혀있지 않다면 락을 변경**

으로 두 연산이 하나로 합쳐진, **원자적 연산**이 된다.

결과적으로 **상대적으로 무거운 동기화 작업 없이도, 락을 잡은 것과 같은 효과**를 달성할 수 있다.

- 대기하는 스레드가 `BLOCKED`, `WAITING` 같은 상태로 변화하는 것이 아니라,

- `while`문을 반복하는 `RUNNABLE` 상태를 유지하면서도 락을 잡았기 때문에 가볍다고 할 수 있다.

### CAS 락의 단점

하지만 스레드가 `RUNNABLE` 상태에서 락을 획득할 때까지 `while`문을 반복하는 것은,

락을 기다리는 스레드가 CPU를 계속 사용하면서 대기한다는 뜻이다.

즉, 락 대상 메서드가 **다소 오래 걸리는 로직**을 가지고 있다면, 오히려 CPU를 비효율적으로 사용하는 결과가 나타날 수 있다.

- 오히려 동기화 락을 사용하면 스레드가 `BLOCKED`, `WAITING` 상태로 바뀌기 때문에

- CPU 자원을 절약하는 방식이 될 수도 있다.

### CAS 락의 효율적인 사용

**안전한 임게 영역이 필요하지만**,

**연산이 길지 않고 매우 짧게 끝날 때에만 사용해야 한다**.

- DB 결과를 대기한다거나, 다른 서버의 요청을 기다리는 등

- 오래 기다리는 작업에 사용하면 CPU를 오히려 계속 사용하며 기다리는 최악의 결과가 나올 수 있다.

### 스핀 락

**스레드가 락이 해제되기를 기다리면서 반복문을 통해 계속해서 확인하는 모습** 때문에, **스핀 락**이라고 부른다.

이런 방식에서 스레드가 락 획득을 대기하는 것을 **스핀 대기** 혹은, CPU 자원을 계속 사용한다는 뜻해서 **바쁜 대기**라고 한다.

스핀 락 방식은 **아주 짧은 CPU 연산을 수행할 때만 사용해야 효율적**이다.

그리고, 통상적으로 스핀 락은 이상에서 다룬 **CAS**를 활용하여 구현이 가능하다.

---

## 정리

### 락 vs CAS 사용 방식

#### CAS의 장점

- **낙관적 동기화** : 락을 걸지 않고도 값을 안전하게 업데이트한다. 충돌이 적은 환경에서 성능이 좋다.

- **락 프리** : 락을 획득하기 위해 대기하는 시간이 없다. 스레드 병렬 처리가 효율적이다.

#### CAS의 단점

- **충돌이 빈번한 경우** : 기본적으로 루프를 돌며 재시도하기 때문에, CPU 자원을 지속적으로 소모한다.

- **스핀락과 유사한 오버헤드** : **스레드 충돌 시 반복적인 재시도**가 발생한다. 스핀락과 유사한 성능 저하를 유발한다.

#### 동기화 락의 장점

- **충돌 관리** : 무조건 하나의 스레드만 리소스에 접근한다. 안정적이다.

- **안정성** : 복잡한 상황에서도 신경쓰지 않을 수 있는 안정성

- **스레드 대기** : 대기 중인 스레드는 CPU를 거의 사용하지 않는다.

#### 동기화 락의 단점

- **락 획득 대기 시간** : 스레드가 락 획득을 위해 대기하는 시간이 길어질 수 있다.

- **컨텍스트 스위칭 오버헤드** : 락 획득을 대기하거나 획득하는 시점에 **스레드 상태 변경**이 발생하고, 이는 **컨텍스트 스위칭**을 유발하여 오버헤드를 증가시킨다.

#### 결론

**일반적으로는 동기화 락을 사용하고, 아주 특별한 경우에 한정하여 CAS를 사용함으로써 최적화를 도모해야 한다**.

#### 실무 관점

실무적으로는 공유 자원에 대한 충돌 가능성이 솔직히 낮은 편이다.

**단순한 연산**의 경우, 락을 거는 것보다 CAS처럼 낙관적인 방식을 **다소 적극적으로 사용해주는 게 좋다**.

자바의 동시성 라이브러리들은 성능 최적화를 위해 CAS 연산을 적극 활용하고 있다. 

따라서 실무에서 CAS를 직접 사용하는 케이스는 매우 드물기는 하지만, 개념적으로 정확히 이해하고 있는 것은 당연히 중요하다고 할 수 있다.


